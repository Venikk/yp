{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é. \n",
    "\n",
    "–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. –í –≤–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫.\n",
    "\n",
    "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75. \n",
    "\n",
    "### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞\n",
    "\n",
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "2. –û–±—É—á–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. \n",
    "3. –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã.\n",
    "\n",
    "–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å *BERT* –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å.\n",
    "\n",
    "### –û–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ñ–∞–π–ª–µ `toxic_comments.csv`. –°—Ç–æ–ª–±–µ—Ü *text* –≤ –Ω—ë–º —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è, –∞ *toxic* ‚Äî —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞  <a class=\"anchor\" id=\"0-bullet\">\n",
    "* [–®–∞–≥ 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞](#1-bullet)\n",
    "* [–®–∞–≥ 2. –û–±—É—á–µ–Ω–∏–µ](#2-bullet)    \n",
    "* [–®–∞–≥ 3. –í—ã–≤–æ–¥—ã](#3-bullet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞<a class=\"anchor\" id=\"1-bullet\"></a>\n",
    "üëà[–Ω–∞–∑–∞–¥ –∫ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é](#0-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">–ü–ª–∞–Ω –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö<span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "    \n",
    "1. –£–±–µ—Ä–µ–º —Å–∏–º–≤–æ–ª—ã, –Ω–µ –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É –∞–ª—Ñ–∞–≤–∏—Ç—É (—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è).\n",
    "2. –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã.\n",
    "3. –†–∞–∑–æ–±—ä–µ–º –≤—ã–±–æ—Ä–∫—É –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ-–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ (4:1).\n",
    "4. –†–∞–∑–æ–±—ä–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ-–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ (3:1).\n",
    "5. –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –º–∞—Å—Å–∏–≤—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±–µ–∏—Ö –≤—ã–±–æ—Ä–æ–∫ –º–µ—Ç–æ–¥–æ–º TF-IDF, –ø–æ–ø—É—Ç–Ω–æ —É–±–µ—Ä–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞.\n",
    "\n",
    "<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–±–µ—Ä–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ –±—É–¥—É—â–∏—Ö —Ä–µ–ª–∏–∑–∞—Ö\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = ''\n",
    "#datasets_path = 'C:/Users/Venik/OneDrive/–î–æ–∫—É–º–µ–Ω—Ç—ã/Yandex_Praktikum/Texts_Project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ—á–∏—Ç–∞–µ–º —Ñ–∞–π–ª\n",
    "toxic_comments = pd.read_csv(datasets_path + '/datasets/toxic_comments.csv')\n",
    "toxic_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>119573</td>\n",
       "      <td>Just an FYI, I added more details to the artic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10875</td>\n",
       "      <td>\"   Please refrain from creating inappropriate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97424</td>\n",
       "      <td>\"\\n\\n Lede is (deliberately?) misleading \\n\\nG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108551</td>\n",
       "      <td>Thanks for contacting CBD. To make it easier f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69872</td>\n",
       "      <td>Pardon my impertinence but I completely re-wro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104829</td>\n",
       "      <td>\"\\nIf so, then they do a pretty good job  they...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10035</td>\n",
       "      <td>\":And A \"\"SINGLE TOPIC\"\" poster who has never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33747</td>\n",
       "      <td>Hector\\nIts missing the piece from The Aeneid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139332</td>\n",
       "      <td>\"\\n\\n GA review of Schindler's List \\n\\nHello,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55473</td>\n",
       "      <td>\"\\nBe WP:CIVIL. I have explained my edits on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "119573  Just an FYI, I added more details to the artic...      0\n",
       "10875   \"   Please refrain from creating inappropriate...      0\n",
       "97424   \"\\n\\n Lede is (deliberately?) misleading \\n\\nG...      0\n",
       "108551  Thanks for contacting CBD. To make it easier f...      0\n",
       "69872   Pardon my impertinence but I completely re-wro...      0\n",
       "104829  \"\\nIf so, then they do a pretty good job  they...      0\n",
       "10035   \":And A \"\"SINGLE TOPIC\"\" poster who has never ...      0\n",
       "33747       Hector\\nIts missing the piece from The Aeneid      0\n",
       "139332  \"\\n\\n GA review of Schindler's List \\n\\nHello,...      0\n",
       "55473   \"\\nBe WP:CIVIL. I have explained my edits on t...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞ –≤—ã–±–æ—Ä–∫–∞\n",
    "toxic_comments['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã –≤ unicode\n",
    "toxic_comments['text'] = toxic_comments['text'].astype('U')\n",
    "toxic_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –∫–æ—Ä–ø—É—Å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "corpus = toxic_comments['text'].values\n",
    "\n",
    "m = Mystem()\n",
    "pattern = r'[^a-zA-Z ]'\n",
    "\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π\n",
    "def resub(text):\n",
    "    text = re.sub(pattern,' ', text)\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "def lemmatize(text):\n",
    "    lemm = m.lemmatize(text)\n",
    "    return \"\".join(lemm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb5a243db3d4ccc94bad2d418d0da02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren t vandalisms just closure on some GAs after I voted at New York Dolls FAC And please don t remove the template from the talk page since I m retired now',\n",
       "       'D aww He matches this background colour I m seemingly stuck with Thanks talk January UTC',\n",
       "       'Hey man I m really not trying to edit war It s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page He seems to care more about the formatting than the actual info',\n",
       "       'More I can t make any real suggestions on improvement I wondered if the section statistics should be later on or a subsection of types of accidents I think the references may need tidying so that they are all in the exact same format ie date format etc I can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up It s listed in the relevant form eg Wikipedia Good article nominations Transport',\n",
       "       'You sir are my hero Any chance you remember what page that s on'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –£–¥–∞–ª–∏–º –∏–∑ –∫–æ—Ä–ø—É—Å–∞ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è\n",
    "for i in notebook.tqdm(range(len(corpus))):\n",
    "    corpus[i] = resub(corpus[i])\n",
    "\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18edfce36c24fb2ae63a953772276f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\\n\",\n",
       "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\\n\",\n",
       "       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\\n\",\n",
       "       '\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominationsTransport  \"\\n',\n",
       "       \"You, sir, are my hero. Any chance you remember what page that's on?\\n\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã –∫–æ—Ä–ø—É—Å–∞\n",
    "for i in notebook.tqdm(range(len(corpus))):\n",
    "    corpus[i] = lemmatize(corpus[i])\n",
    "\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>91597</td>\n",
       "      <td>Austin Bourke was a meteorologist. He was invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99945</td>\n",
       "      <td>\"\\nThe problem is that there is no \"\"generally...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105110</td>\n",
       "      <td>Djehuty\\nHey, thought I'd let you know I start...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4959</td>\n",
       "      <td>\" cannot decipher, and punitive actions.  As t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16266</td>\n",
       "      <td>Sounds good to me. What do you think of the fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81714</td>\n",
       "      <td>\"\\n\\n Re: Reverting \\n\\nIs reverting where you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73965</td>\n",
       "      <td>\"\\n\\n That userbox.... \\n\\nHello Chavatshimsho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75573</td>\n",
       "      <td>\"Please do not add nonsense to Wikipedia. It i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8536</td>\n",
       "      <td>And then there's Henry IV style - don't look n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124632</td>\n",
       "      <td>\"::: Honestly, They aren't really \"\"experiment...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "91597   Austin Bourke was a meteorologist. He was invo...      0\n",
       "99945   \"\\nThe problem is that there is no \"\"generally...      0\n",
       "105110  Djehuty\\nHey, thought I'd let you know I start...      0\n",
       "4959    \" cannot decipher, and punitive actions.  As t...      0\n",
       "16266   Sounds good to me. What do you think of the fi...      0\n",
       "81714   \"\\n\\n Re: Reverting \\n\\nIs reverting where you...      0\n",
       "73965   \"\\n\\n That userbox.... \\n\\nHello Chavatshimsho...      0\n",
       "75573   \"Please do not add nonsense to Wikipedia. It i...      0\n",
       "8536    And then there's Henry IV style - don't look n...      0\n",
       "124632  \"::: Honestly, They aren't really \"\"experiment...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ó–∞–º–µ–Ω–∏–º —Ç–µ–∫—Å—Ç—ã –≤ –¥–∞—Ç–µ—Å–µ—Ç–µ\n",
    "toxic_comments['text'] = corpus\n",
    "\n",
    "del corpus\n",
    "\n",
    "toxic_comments.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments.to_csv(datasets_path + 'toxic_comments_lemmatized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–∏–º –≤—ã–±–æ—Ä–∫–∏\n",
    "train_valid, test = train_test_split(toxic_comments, \n",
    "                                     test_size = 0.2,\n",
    "                                     stratify = toxic_comments['toxic'])\n",
    "\n",
    "train, valid = train_test_split(train_valid, \n",
    "                                test_size = 0.25,\n",
    "                                stratify = train_valid['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95742,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –í—ã–¥–µ–ª–∏–º —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –∏ –∫–æ—Ä–ø—É—Å –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "corpus_train = train['text'].values\n",
    "target_train = train['toxic']\n",
    "corpus_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31914,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –í—ã–¥–µ–ª–∏–º —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –∏ –∫–æ—Ä–ø—É—Å –∏–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "corpus_valid = valid['text'].values\n",
    "target_valid = valid['toxic']\n",
    "corpus_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31915,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –í—ã–¥–µ–ª–∏–º —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –∏ –∫–æ—Ä–ø—É—Å –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "corpus_test = test['text'].values\n",
    "target_test = test['toxic']\n",
    "corpus_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95742, 139459)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º –º–∞—Å—Å–∏–≤ —Å–ª–æ–≤ –±–µ–∑ —Å–º—ã—Å–ª–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –º–∞—Å—Å–∏–≤—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ—Ç–æ–¥–æ–º TF-IDF\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words, ngram_range = (1, 1))\n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train)\n",
    "tf_idf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31914, 139459)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_valid = count_tf_idf.transform(corpus_valid)\n",
    "tf_idf_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31915, 139459)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_test = count_tf_idf.transform(corpus_test)\n",
    "tf_idf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">–í—ã–≤–æ–¥—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö<span>\n",
    "\n",
    " <span style=\"color:blue\">\n",
    "–ò–∑ —Ç–µ–∫—Å—Ç–∞ –±—ã–ª–∏ —É–±—Ä–∞–Ω—ã —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–ª–æ–≤–∞ –Ω–µ –∏–º–µ—é—â–∏–µ —Å–º—ã—Å–ª–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏. –ü—Ä–æ–≤–µ–¥–µ–Ω–∞ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –±—ã–ª–∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ-–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –∏ —Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∏. –≠—Ç–∏ –≤—ã–±–æ—Ä–∫–∏ –º—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–ª–∏ –≤ –º–∞—Å—Å–∏–≤—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "\n",
    "<b>–ü—Ä–∏—Å—Ç—É–ø–∏–º –∫ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π.</b>\n",
    "<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. –û–±—É—á–µ–Ω–∏–µ<a class=\"anchor\" id=\"2-bullet\"></a>\n",
    "üëà[–Ω–∞–∑–∞–¥ –∫ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é](#0-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">–ü–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π<span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "    \n",
    "1. –ü—Ä–æ–≤–µ–¥–µ–º –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫–∏ f1 –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. –ü–æ–¥–±–µ—Ä–µ–º –ª—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏.\n",
    "2. –°—Ä–∞–≤–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "3. –û–±—É—á–∏–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –¥–ª—è –Ω–µ–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–∞ –≤—ã–±–æ—Ä–∫–µ, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ –∏ –≤—ã–≤–µ–¥–µ–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å f1 –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏.\n",
    "4. –í—ã–±–µ—Ä–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å.\n",
    "    \n",
    "<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–¥–∏–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –≤ –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ–º –ø–∏—Å–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "compare = {'model_name' : [],\n",
    "           'param1_name' : [],\n",
    "           'param1_value' : [],\n",
    "           'param2_name' : [],\n",
    "           'param2_value' : [],\n",
    "           'param3_name' : [],\n",
    "           'param3_value' : [],\n",
    "           'f1' : []\n",
    "           }\n",
    "\n",
    "compare_data_models = pd.DataFrame(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏ –≤ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "def add_model_params(model_name,\n",
    "                     param1_name,\n",
    "                     param1_value,\n",
    "                     param2_name,\n",
    "                     param2_value,\n",
    "                     param3_name,\n",
    "                     param3_value,\n",
    "                     f1,\n",
    "                     compare_data):\n",
    "    \n",
    "    compare_data = compare_data.append(pd.DataFrame([[model_name,\n",
    "                                                      param1_name,\n",
    "                                                      param1_value,\n",
    "                                                      param2_name,\n",
    "                                                      param2_value,\n",
    "                                                      param3_name,\n",
    "                                                      param3_value,\n",
    "                                                      f1]], \n",
    "                                                      columns = ['model_name',\n",
    "                                                                 'param1_name',\n",
    "                                                                 'param1_value',\n",
    "                                                                 'param2_name',\n",
    "                                                                 'param2_value',\n",
    "                                                                 'param3_name',\n",
    "                                                                 'param3_value',\n",
    "                                                                 'f1']),\n",
    "                                                      ignore_index=True)\n",
    "    \n",
    "    return compare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_f1(model,\n",
    "             train_features,\n",
    "             train_target,\n",
    "             valid_features,\n",
    "             valid_target):\n",
    "    \n",
    "    model.fit(train_features,train_target)\n",
    "    predictions = model.predict(valid_features)\n",
    "    return f1_score(valid_target, predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">–ù–∞—á–Ω–µ–º –∞–Ω–∞–ª–∏–∑ —Å –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>param1_name</th>\n",
       "      <th>param1_value</th>\n",
       "      <th>param2_name</th>\n",
       "      <th>param2_value</th>\n",
       "      <th>param3_name</th>\n",
       "      <th>param3_value</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name param1_name  param1_value param2_name  param2_value  \\\n",
       "0  LogisticRegression        None           0.0        None           0.0   \n",
       "\n",
       "  param3_name  param3_value        f1  \n",
       "0        None           0.0  0.703939  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "\n",
    "current_f1 = check_f1(model,\n",
    "                     tf_idf_train,\n",
    "                     target_train,\n",
    "                     tf_idf_valid,\n",
    "                     target_valid)\n",
    "\n",
    "compare_data_models = add_model_params('LogisticRegression',\n",
    "                                        'None', \n",
    "                                        0,\n",
    "                                        'None',\n",
    "                                        0,\n",
    "                                        'None',\n",
    "                                        0,\n",
    "                                         current_f1,\n",
    "                                        compare_data_models) \n",
    "\n",
    "compare_data_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "\n",
    "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –Ω–µ–º–Ω–æ–≥–æ –Ω–µ –¥–æ—Ç—è–≥–∏–≤–∞–µ—Ç –¥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ F1 = 0,75.\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –≤–æ–∑—å–º–µ–º –º–æ–¥–µ–ª—å AdaBoost –∏ –ø–æ–¥–±–µ—Ä–µ–º –¥–ª—è –Ω–µ–µ –ø–∞—Ä–∞–º–µ—Ç—Ä \"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω—â–∏–∫–æ–≤\". –î–ª—è –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–±–µ—Ä–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 1000 –¥–æ 1200 —Å —à–∞–≥–æ–º 100.\n",
    "    \n",
    "<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9408dc41247e41098fbd6067e467c886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7def8349a088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                          \u001b[0mtarget_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                          \u001b[0mtf_idf_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                          target_valid)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_f1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcurrent_f1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-88a9b6d8c91c>\u001b[0m in \u001b[0;36mcheck_f1\u001b[0;34m(model, train_features, train_target, valid_features, valid_target)\u001b[0m\n\u001b[1;32m      5\u001b[0m              valid_target):\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \"\"\"\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# AdaBoost (–ø–æ–¥–±–æ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω—â–∏–∫–æ–≤)\n",
    "\n",
    "best_f1 = 0\n",
    "best_n_estimators = 0\n",
    "\n",
    "for n_estimators in notebook.tqdm(range(1000, 1201, 100)):\n",
    "    \n",
    "    model = AdaBoostClassifier(random_state=12345,\n",
    "                               n_estimators = n_estimators)\n",
    "\n",
    "    current_f1 = check_f1(model,\n",
    "                         tf_idf_train,\n",
    "                         target_train,\n",
    "                         tf_idf_valid,\n",
    "                         target_valid)\n",
    "       \n",
    "    if best_f1 < current_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_n_estimators = n_estimators\n",
    "        \n",
    "print('–õ—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω—â–∏–∫–æ–≤ –¥–ª—è AdaBoost:', \n",
    "      best_n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_n_estimators' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-86681256bcbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m compare_data_models = add_model_params('AdaBoost', \n\u001b[1;32m      2\u001b[0m                                         \u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                         \u001b[0mbest_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                         \u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                         \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_n_estimators' is not defined"
     ]
    }
   ],
   "source": [
    "compare_data_models = add_model_params('AdaBoost', \n",
    "                                        'n_estimators', \n",
    "                                        best_n_estimators,\n",
    "                                        'None',\n",
    "                                        0,\n",
    "                                        'None',\n",
    "                                        0,\n",
    "                                        best_f1,\n",
    "                                        compare_data_models) \n",
    "\n",
    "compare_data_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "\n",
    "–ú–æ–¥–µ–ª—å AdaBoost –ø–æ–∫–∞–∑–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π –Ω–∞–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ. \n",
    "–¢–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä–∏–º –∫–∞–∫ —Å–µ–±—è –ø–æ–≤–µ–¥—É—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–æ—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ, —Å–æ—Å—Ç–æ—è—â–µ–º –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–æ–∫.\n",
    "    \n",
    "–ü—Ä–æ–≤–µ—Ä–∫—É –±—É–¥–µ–º –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ.\n",
    "    \n",
    "<span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–¥–∏–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –≤ –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ–º –ø–∏—Å–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "compare = {'model_name' : [],\n",
    "           'f1' : []\n",
    "           }\n",
    "\n",
    "compare_best_models = pd.DataFrame(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏ –≤ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "def add_best_model_f1(model_name,\n",
    "                      f1,\n",
    "                      compare_data):\n",
    "    \n",
    "    compare_data = compare_data.append(pd.DataFrame([[model_name,\n",
    "                                                      f1]], \n",
    "                                                      columns = ['model_name',\n",
    "                                                                  'f1']),\n",
    "                                                      ignore_index=True)\n",
    "    \n",
    "    return compare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<127656x125435 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3454591 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–±—â–∏–π –º–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "tf_idf_train_valid = sp.vstack((tf_idf_train,tf_idf_valid))\n",
    "tf_idf_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–±—â–∏–π –º–∞—Å—Å–∏–≤ —Ü–µ–ª–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "target_train_valid = pd.concat([target_train,target_valid])\n",
    "target_train_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9198ddc0d48945218692e609ad238e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.735179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.769950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name        f1\n",
       "0  LogisticRegression  0.735179\n",
       "1            AdaBoost  0.769950"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –í—ã—á–∏—Å–ª–∏–º –∏ —Å—Ä–∞–≤–Ω–∏–º f1 –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "for i in notebook.tqdm(range(compare_data_models.shape[0])):\n",
    "    \n",
    "    model_name = compare_data_models.iloc[i]['model_name']\n",
    "    param1 = int(compare_data_models.iloc[i]['param1_value'])\n",
    "    param2 = int(compare_data_models.iloc[i]['param2_value'])\n",
    "    param3 = int(compare_data_models.iloc[i]['param3_value'])\n",
    "\n",
    "    if model_name == 'LogisticRegression':\n",
    "        model = LogisticRegression(random_state = 12345)\n",
    "    \n",
    "    elif model_name == 'AdaBoost':\n",
    "        model = AdaBoostClassifier(random_state=12345,\n",
    "                                   n_estimators = param1)\n",
    "        \n",
    "    f1 = check_f1(model,\n",
    "                  tf_idf_train_valid,\n",
    "                  target_train_valid,\n",
    "                  tf_idf_test,\n",
    "                  target_test)\n",
    "    \n",
    "    compare_best_models = add_best_model_f1(model_name, \n",
    "                                           f1,\n",
    "                                           compare_best_models) \n",
    "\n",
    "\n",
    "compare_best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. –í—ã–≤–æ–¥—ã<a class=\"anchor\" id=\"3-bullet\"></a>\n",
    "üëà[–Ω–∞–∑–∞–¥ –∫ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é](#0-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "\n",
    "–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –º—ã –æ–±–æ—à–ª–∏—Å—å –±–µ–∑ \"—Ç—è–∂–µ–ª—ã—Ö\" –º–æ–¥–µ–ª–µ–π, –≤—Ä–æ–¥–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞. –ï—Å–ª–∏ –±—ã —Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –±—ã–ª–æ –Ω–µ–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ (–≤—Å–µ–≥–æ –Ω–∞ 2%), –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –≤–∑—è—Ç—å –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤ –º–æ–¥–µ–ª—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏. –û–Ω–∞ –ø–æ–∫–∞–∑–∞–ª–∞ F1 = 0,735.\n",
    "\n",
    "–ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å –∏–∑ –±–∞–∑–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞ \"–∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö\" –º–æ–¥–µ–ª–µ–π AdaBoostClassifier –ø–æ–∫–∞–∑–∞–ª–∞ —Å–µ–±—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ –∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ F1 = 0,77. –≠—Ç–æ–≥–æ –≤–ø–æ–ª–Ω–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.\n",
    "    \n",
    "<span>\n",
    "    \n",
    "<span style=\"color:red\"><b>\n",
    "    –ú–æ–¥–µ–ª—å AdaBoostClassifier –º—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.\n",
    "</b><span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook –æ—Ç–∫—Ä—ã—Ç\n",
    "- [x]  –í–µ—Å—å –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫\n",
    "- [x]  –Ø—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "- [x]  –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã\n",
    "- [x]  –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã\n",
    "- [x]  –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75\n",
    "- [x]  –í—ã–≤–æ–¥—ã –Ω–∞–ø–∏—Å–∞–Ω—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
